{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inital Mucking Around with BERT\n",
    "\n",
    "To add additional vocab, see https://github.com/google-research/bert/issues/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T21:50:13.467176Z",
     "start_time": "2019-01-04T21:50:13.463175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** BERT pretrained directory: E:\\Jupyter\\keras-bert\\getting_it_running\\uncased_L-12_H-768_A-12 *****\n"
     ]
    }
   ],
   "source": [
    "#place unzipped BERT model files in same level dir\n",
    "#https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "\n",
    "import os\n",
    "UPLOAD_TIME = '2018_10_18' #@param {type:\"string\"}\n",
    "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
    "BERT_PRETRAINED_DIR = os.path.realpath(BERT_MODEL)\n",
    "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:41:25.155456Z",
     "start_time": "2019-01-04T19:41:09.275520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "Input-Token (InputLayer)               (None, 512)                0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)             (None, 512)                0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding)       [(None, 512, 768), (30522, 23440896      Input-Token[0][0]                       \n",
      "________________________________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)          (None, 512, 768)           1536          Input-Segment[0][0]                     \n",
      "________________________________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)          (None, 512, 768)           0             Embedding-Token[0][0]                   \n",
      "                                                                                Embedding-Segment[0][0]                 \n",
      "________________________________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmbedding) (None, 512, 768)           393216        Embedding-Token-Segment[0][0]           \n",
      "________________________________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)            (None, 512, 768)           0             Embedding-Position[0][0]                \n",
      "________________________________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalization)    (None, 512, 768)           1536          Embedding-Dropout[0][0]                 \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Embedding-Norm[0][0]                    \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Embedding-Norm[0][0]                    \n",
      "                                                                                Encoder-1-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-1-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-1-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-1-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-1-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-1-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-1-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-2-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-2-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-2-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-2-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-2-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-2-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-2-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-3-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-3-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-3-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-3-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-3-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-3-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-3-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-4-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-4-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-4-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-4-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-4-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-4-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-4-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-5-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-5-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-5-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-5-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-5-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-5-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-5-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-6-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-6-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-6-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-6-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-6-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-6-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-6-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-7-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-7-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-7-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-7-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-7-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-7-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-7-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-8-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-8-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-8-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-8-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-8-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-8-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention[0][0]  \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-8-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-9-MultiHeadSelfAttention-Dropout\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-9-MultiHeadSelfAttention-Add[0][\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-9-FeedForward[0][0]             \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
      "                                                                                Encoder-9-FeedForward-Dropout[0][0]     \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-9-FeedForward-Add[0][0]         \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-9-FeedForward-Norm[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention[0][0] \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-9-FeedForward-Norm[0][0]        \n",
      "                                                                                Encoder-10-MultiHeadSelfAttention-Dropou\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-10-MultiHeadSelfAttention-Add[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-10-MultiHeadSelfAttention-Norm[0\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-10-FeedForward[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention-Norm[0\n",
      "                                                                                Encoder-10-FeedForward-Dropout[0][0]    \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-10-FeedForward-Add[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-10-FeedForward-Norm[0][0]       \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention[0][0] \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-10-FeedForward-Norm[0][0]       \n",
      "                                                                                Encoder-11-MultiHeadSelfAttention-Dropou\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-11-MultiHeadSelfAttention-Add[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-11-MultiHeadSelfAttention-Norm[0\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-11-FeedForward[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention-Norm[0\n",
      "                                                                                Encoder-11-FeedForward-Dropout[0][0]    \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-11-FeedForward-Add[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-11-FeedForward-Norm[0][0]       \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention[0][0] \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-11-FeedForward-Norm[0][0]       \n",
      "                                                                                Encoder-12-MultiHeadSelfAttention-Dropou\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-12-MultiHeadSelfAttention-Add[0]\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-12-MultiHeadSelfAttention-Norm[0\n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-12-FeedForward[0][0]            \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention-Norm[0\n",
      "                                                                                Encoder-12-FeedForward-Dropout[0][0]    \n",
      "________________________________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-12-FeedForward-Add[0][0]        \n",
      "________________________________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)                      (None, 512, 768)           590592        Encoder-12-FeedForward-Norm[0][0]       \n",
      "________________________________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)          (None, 512, 768)           1536          MLM-Dense[0][0]                         \n",
      "________________________________________________________________________________________________________________________\n",
      "Extract (Extract)                      (None, 768)                0             Encoder-12-FeedForward-Norm[0][0]       \n",
      "________________________________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)          (None, 512, 30522)         30522         MLM-Norm[0][0]                          \n",
      "                                                                                Embedding-Token[0][1]                   \n",
      "________________________________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)              (None, 512)                0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)                      (None, 768)                590592        Extract[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "MLM (Masked)                           (None, 512, 30522)         0             MLM-Sim[0][0]                           \n",
      "                                                                                Input-Masked[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "NSP (Dense)                            (None, 2)                  1538          NSP-Dense[0][0]                         \n",
      "========================================================================================================================\n",
      "Total params: 110,106,428\n",
      "Trainable params: 110,106,428\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from keras_bert.loader import load_trained_model_from_checkpoint\n",
    "from keras_bert.bert import *\n",
    "config_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "checkpoint_file = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "model = load_trained_model_from_checkpoint(config_file, checkpoint_file, training=True)\n",
    "\n",
    "model.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:58:26.685306Z",
     "start_time": "2019-01-04T19:58:26.620326Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile('adam', 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T20:03:44.237258Z",
     "start_time": "2019-01-04T20:03:44.228256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Jupyter\\\\keras-bert\\\\getting_it_running\\\\uncased_L-12_H-768_A-12\\\\vocab.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_path = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T22:02:15.586119Z",
     "start_time": "2019-01-04T22:02:15.479520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'on', '01/04/2019', 'at', '01:29', 'the', 'control', 'room', 'received', 'alarm', 'window', '5b02d', ',', 'pps', 'trouble', '/', 'gnd', ',and', 'rj', 'point', 'sbys36,', 'plant', 'protection', 'system', 'channel', 'd', 'ground.', 'the', 'alarm', 'locked', 'in', 'for', '45', 'minutes', 'then', '[MASK]', '.', 'the', 'alarm', 'response', 'was', 'followed', 'and', 'no', '[MASK]', 'were', 'identified', '[SEP]', 'the', 'ground', 'alarm', 'light', 'on', 'thefront', 'of', 'pps', 'cabinet', 'd', 'is', 'on', 'which', 'is', 'normal', ',', 'meaning', 'there', 'is', 'no', 'ground', 'indicated', '[SEP]', 'wrote', 'cr', 'torequest', 'support', 'from', 'i&c', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "bsz = 8\n",
    "MASK = ['[MASK]']\n",
    "CLS = ['[CLS]']\n",
    "SEP = ['[SEP]']\n",
    "UNK = ['[UNK]']\n",
    "\n",
    "tokens = CLS + 'VALVE'.lower().split() + 'GLOBE LESS EQ'.lower().split() + MASK + 'SEAL 0.75 IN 2173# \\\n",
    "PER ANSI B16.34-1981 FORGED SSBODY BOLTED BONNET, SOCKET WELD'.lower().split() + SEP + 'MUST COMPLY WITH ASME B&PV CODE, \\\n",
    "SECT III, CL 2, 1974 ED W75 ADD AND SPEC CMTR FOR BODY (SA182 TP 316L), INDICATOR TUBE (SA479 GR 316), \\\n",
    "BONNET TUBE (SA479 GR XM-19), MAIN DISC (SA564 GR 630), AND FIXED CORE (A276 GR 410 OR A479 GR 410), \\\n",
    "NOREM 02A HARD FACING'.lower().split() + SEP + 'MUST PROVIDE CERTIFICATION TO EQUIP QUALIFICATION AND SEISMIC REQUIREMENTS PER \\\n",
    "SPEC, PT/MT FOR HARD FACING/OVERLAY'.lower().split() + SEP\n",
    "\n",
    "#develop\n",
    "tokens = CLS + 'Attempting to'.lower().split() + MASK + 'inventions he could patent and market, \\\n",
    "Tesla conducted a range of experiments with mechanical oscillators generators \\\n",
    "electrical discharge tubes and early X-ray imaging'.lower().split() + SEP + \\\n",
    "'He also built a wireless controlled boat , one of the first ever exhibited'.lower().split() + SEP\n",
    "\n",
    "#cleared\n",
    "tokens = CLS + 'ON 01/04/2019 at 01:29 The Control Room received alarm window 5B02D , PPS TROUBLE / GND ,\\\n",
    "and RJ point SBYS36, Plant Protection System Channel D Ground. The alarm locked in for 45 minutes \\\n",
    "then'.lower().split() + MASK +\\\n",
    "'. The alarm response was followed and no abnormalities were identified'.lower().split() + SEP + 'The ground alarm light on the\\\n",
    "front of PPS Cabinet D is ON which is normal , meaning there is no ground indicated'.lower().split() + SEP + 'Wrote CR to\\\n",
    "request support from I&C'.lower().split() + SEP\n",
    "\n",
    "#cleared, None:There was no word there\n",
    "tokens = CLS + 'ON 01/04/2019 at 01:29 The Control Room received alarm window 5B02D , PPS TROUBLE / GND ,\\\n",
    "and RJ point SBYS36, Plant Protection System Channel D Ground. The alarm locked in for 45 minutes \\\n",
    "then'.lower().split() + MASK +\\\n",
    "'. The alarm response was followed and no'.lower().split() + MASK +  'abnormalities were identified'.lower().split() + SEP + 'The ground alarm light on the\\\n",
    "front of PPS Cabinet D is ON which is normal , meaning there is no ground indicated'.lower().split() + SEP + 'Wrote CR to\\\n",
    "request support from I&C'.lower().split() + SEP\n",
    "\n",
    "#cleared, abnormalities\n",
    "tokens = CLS + 'ON 01/04/2019 at 01:29 The Control Room received alarm window 5B02D , PPS TROUBLE / GND ,\\\n",
    "and RJ point SBYS36, Plant Protection System Channel D Ground. The alarm locked in for 45 minutes \\\n",
    "then'.lower().split() + MASK +\\\n",
    "'. The alarm response was followed and no'.lower().split() + MASK +  'were identified'.lower().split() + SEP + 'The ground alarm light on the\\\n",
    "front of PPS Cabinet D is ON which is normal , meaning there is no ground indicated'.lower().split() + SEP + 'Wrote CR to\\\n",
    "request support from I&C'.lower().split() + SEP\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "token_dict = {}\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "token_dict_rev = {v: k for k, v in token_dict.items()}\n",
    "\n",
    "def token_lookup(token):\n",
    "    try:\n",
    "        x = token_dict[token]\n",
    "        return x\n",
    "    except KeyError:\n",
    "        return token_dict['[UNK]']\n",
    "    \n",
    "token_input = np.asarray([[token_lookup(token) for token in tokens] + [0] * (512 - len(tokens)) for i in range(bsz)])\n",
    "seg_input = np.asarray([[0] * len(tokens) + [0] * (512 - len(tokens)) for i in range(bsz)])\n",
    "mask_input = np.asarray([[0, 1, 1] + [0] * (512 - 3) for i in range(bsz)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T22:02:16.287972Z",
     "start_time": "2019-01-04T22:02:15.672195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  2006   100  2012   100  1996  2491  2282  2363  8598  3332   100\n",
      "  1010   100  4390  1013   100   100   100  2391   100  3269  3860  2291\n",
      "  3149  1040   100  1996  8598  5299  1999  2005  3429  2781  2059   103\n",
      "  1012  1996  8598  3433  2001  2628  1998  2053   103  2020  4453   102\n",
      "  1996  2598  8598  2422  2006   100  1997   100  5239  1040  2003  2006\n",
      "  2029  2003  3671  1010  3574  2045  2003  2053  2598  5393   102  2626\n",
      " 13675   100  2490  2013   100   102]\n",
      "[1012 2006  100 2012  100 1996 2491 2282 2363 8598 3332  100 1010  100\n",
      "  100 1013  100  100  100 2391  100 3269 3860 2291 3149 1040  100 1996\n",
      " 8598 5299 1999 2005 3429 2781 2059 3030 1012 1996 8598 3433 2001 2628\n",
      " 1998 2053 3471 2020 4453 1012 1996 2598 8598 2422 2006  100 1997  100\n",
      " 5239 1040 2003 2006 2029 2003 3671 1010 3574 2045 2003 2053 2598 1012\n",
      " 1012  100 1024  100 2490 2013 1012 1012]\n",
      "['on', '[UNK]', 'at', '[UNK]', 'the', 'control', 'room', 'received', 'alarm', 'window', '[UNK]', ',', '[UNK]', '[UNK]', '/', '[UNK]', '[UNK]', '[UNK]', 'point', '[UNK]', 'plant', 'protection', 'system', 'channel', 'd', '[UNK]', 'the', 'alarm', 'locked', 'in', 'for', '45', 'minutes', 'then', 'stopped', '.', 'the', 'alarm', 'response', 'was', 'followed', 'and', 'no', 'problems', 'were', 'identified', '.', 'the', 'ground', 'alarm', 'light', 'on', '[UNK]', 'of', '[UNK]', 'cabinet', 'd', 'is', 'on', 'which', 'is', 'normal', ',', 'meaning', 'there', 'is', 'no', 'ground', '.', '.', '[UNK]', ':', '[UNK]', 'support', 'from', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(token_input[0][:len(tokens)])\n",
    "predicts = model.predict([token_input, seg_input, mask_input])[0]\n",
    "predicts = np.argmax(predicts, axis=-1)\n",
    "print(predicts[0][:len(tokens)])\n",
    "print(list(map(lambda x: token_dict_rev[x], predicts[0][1:len(tokens)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
